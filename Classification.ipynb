{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409cb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9850b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Define a function to extract labels from filenames\n",
    "def extract_label_from_filename(filename):\n",
    "    # Assuming filenames are in the format: subject_task.bdf\n",
    "    task = filename.split('_')[1].split('.')[0].split('-')[1]\n",
    "    return task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1017e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Convert to DataFrame\n",
    "def convert_bdf_to_dataframe(bdf_filename):\n",
    "    \n",
    "    # Loading Data\n",
    "    raw_data = mne.io.read_raw_bdf(bdf_filename, preload=True)\n",
    "    ## raw_data._data = raw_data._data ** 2\n",
    "    \n",
    "    # ICA\n",
    "    n_components = 15\n",
    "    ica = ICA(n_components=n_components, random_state=97, max_iter=800)\n",
    "    ica.fit(raw_data)\n",
    "    \n",
    "    # Exclude components\n",
    "    components_to_exclude = [7, 9]\n",
    "    raw_cleaned = ica.apply(raw_data.copy(), exclude=components_to_exclude)\n",
    "    \n",
    "    # convert to dataframe\n",
    "    eeg_data_raw = raw_cleaned.get_data()\n",
    "    channel_names = raw_cleaned.ch_names\n",
    "    time_index = raw_cleaned.times\n",
    "        \n",
    "    eeg_data = pd.DataFrame(data=eeg_data_raw.T, columns=channel_names, index=time_index)\n",
    "    col_names = [\"AF3\", \"AF4\", \"P7\", \"P8\", \"FC5\", \"FC6\", \"T7\", \"T8\", \"Fp1\", \"Fp2\", \"Fpz\", \"O1\", \"O2\"]\n",
    "    eeg_data = eeg_data[col_names]\n",
    "    \n",
    "    # Group by each second\n",
    "    segment_size = 1024\n",
    "    num_segments = len(eeg_data) // segment_size\n",
    "    reduced_df = pd.DataFrame(columns=eeg_data.columns)\n",
    "    for i in range(num_segments):\n",
    "        start_idx = i * segment_size\n",
    "        end_idx = (i + 1) * segment_size\n",
    "        segment_data = eeg_data.iloc[start_idx:end_idx]    \n",
    "        mean_values = segment_data.mean()\n",
    "        reduced_df = reduced_df.append(mean_values, ignore_index=True)\n",
    "\n",
    "    return reduced_df, raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1378af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols = [\"AF3\", \"AF4\", \"P7\", \"P8\", \"FC5\", \"FC6\", \"T7\", \"T8\", \"Fp1\", \"Fp2\", \"Fpz\", \"O1\", \"O2\"]\n",
    "main_df_cols = []\n",
    "\n",
    "for col in req_cols:\n",
    "    if col == 'O1' or col == 'O2':\n",
    "        main_df_cols.append(f'{col} gamma mean')\n",
    "        main_df_cols.append(f'{col} gamma psd_mean')\n",
    "    else:\n",
    "        main_df_cols.append(f'{col} alpha mean')\n",
    "        main_df_cols.append(f'{col} alpha psd_mean')\n",
    "        main_df_cols.append(f'{col} beta mean')\n",
    "        main_df_cols.append(f'{col} beta psd_mean')\n",
    "main_df_cols.append('task')\n",
    "        \n",
    "main_df = pd.DataFrame(columns=main_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7790c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3 alpha mean</th>\n",
       "      <th>AF3 alpha psd_mean</th>\n",
       "      <th>AF3 beta mean</th>\n",
       "      <th>AF3 beta psd_mean</th>\n",
       "      <th>AF4 alpha mean</th>\n",
       "      <th>AF4 alpha psd_mean</th>\n",
       "      <th>AF4 beta mean</th>\n",
       "      <th>AF4 beta psd_mean</th>\n",
       "      <th>P7 alpha mean</th>\n",
       "      <th>P7 alpha psd_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fp2 beta psd_mean</th>\n",
       "      <th>Fpz alpha mean</th>\n",
       "      <th>Fpz alpha psd_mean</th>\n",
       "      <th>Fpz beta mean</th>\n",
       "      <th>Fpz beta psd_mean</th>\n",
       "      <th>O1 gamma mean</th>\n",
       "      <th>O1 gamma psd_mean</th>\n",
       "      <th>O2 gamma mean</th>\n",
       "      <th>O2 gamma psd_mean</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AF3 alpha mean, AF3 alpha psd_mean, AF3 beta mean, AF3 beta psd_mean, AF4 alpha mean, AF4 alpha psd_mean, AF4 beta mean, AF4 beta psd_mean, P7 alpha mean, P7 alpha psd_mean, P7 beta mean, P7 beta psd_mean, P8 alpha mean, P8 alpha psd_mean, P8 beta mean, P8 beta psd_mean, FC5 alpha mean, FC5 alpha psd_mean, FC5 beta mean, FC5 beta psd_mean, FC6 alpha mean, FC6 alpha psd_mean, FC6 beta mean, FC6 beta psd_mean, T7 alpha mean, T7 alpha psd_mean, T7 beta mean, T7 beta psd_mean, T8 alpha mean, T8 alpha psd_mean, T8 beta mean, T8 beta psd_mean, Fp1 alpha mean, Fp1 alpha psd_mean, Fp1 beta mean, Fp1 beta psd_mean, Fp2 alpha mean, Fp2 alpha psd_mean, Fp2 beta mean, Fp2 beta psd_mean, Fpz alpha mean, Fpz alpha psd_mean, Fpz beta mean, Fpz beta psd_mean, O1 gamma mean, O1 gamma psd_mean, O2 gamma mean, O2 gamma psd_mean, task]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 49 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb64f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mean_and_psd_mean(reduced_decomp_df, label):\n",
    "    values = []\n",
    "    req_channels = reduced_decomp_df.columns\n",
    "    for channel in req_channels:\n",
    "        mean_val = reduced_decomp_df[channel].mean()\n",
    "        _, psd = welch(reduced_decomp_df[channel], fs=256)\n",
    "        values.append(mean_val)\n",
    "        values.append(psd.mean())\n",
    "    values.append(label)\n",
    "    main_df.loc[main_df.shape[0]] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f2c3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir1 = 'C:\\Dataset_meditation\\Dataset-1'# Replace with the path to your .bdf data directory (/Dataset - 3/)\n",
    "data_dir2 = 'C:\\Dataset_meditation\\Dataset-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a37e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Initialize empty lists to store data and labels\n",
    "data = []\n",
    "labels = []\n",
    "raw_eegdata = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(data_dir1):\n",
    "    if filename.endswith('.bdf'):\n",
    "        # Convert the .bdf file to a DataFrame\n",
    "        eeg_data, eeg_raw = convert_bdf_to_dataframe(os.path.join(data_dir1, filename))\n",
    "        \n",
    "        # Extract labels from filenames\n",
    "        label = extract_label_from_filename(filename)\n",
    "#         # Append data and labels\n",
    "        raw_eegdata.append(eeg_raw)\n",
    "    \n",
    "        channel_name_1 = ['O1', 'O2']\n",
    "        channel_name_2 = [\"AF3\", \"AF4\", \"P7\", \"P8\", \"FC5\", \"FC6\", \"T7\", \"T8\", \"Fp1\", \"Fp2\", \"Fpz\"]  # Add more channel names as needed\n",
    "\n",
    "#         # Create dictionaries to store the filtered data\n",
    "        eeg_dataframe = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # Loop through each channel and filter data\n",
    "        for channel_name in channel_name_2:\n",
    "            eeg_channel = eeg_raw.copy().pick_channels([channel_name])\n",
    "    \n",
    "            # Filter for Alpha (8-13 Hz)\n",
    "            alpha_filtered = eeg_channel.filter(l_freq=8, h_freq=13)\n",
    "            alpha_decomp = alpha_filtered.get_data()[0]\n",
    "            eeg_dataframe[f'{channel_name} alpha'] = alpha_decomp\n",
    "    \n",
    "            # Filter for Beta (13-30 Hz)\n",
    "            beta_filtered = eeg_channel.filter(l_freq=13, h_freq=30)\n",
    "            beta_decomp = beta_filtered.get_data()[0]\n",
    "            eeg_dataframe[f'{channel_name} beta'] = beta_decomp\n",
    "    \n",
    "        for channel_name in channel_name_1:\n",
    "            eeg_channel = eeg_raw.copy().pick_channels([channel_name])\n",
    "    \n",
    "            # Filter for Gamma (30-40 Hz)\n",
    "            gamma_filtered = eeg_channel.filter(l_freq=30, h_freq=40)\n",
    "            gamma_decomp = gamma_filtered.get_data()[0]\n",
    "            eeg_dataframe[f'{channel_name} gamma'] = gamma_decomp\n",
    "\n",
    "        # Grouping data for each second\n",
    "        segment_size = 1024\n",
    "        num_segments = len(eeg_dataframe) // segment_size\n",
    "        reduced_decomp_df = pd.DataFrame(columns=eeg_dataframe.columns)\n",
    "        for i in range(num_segments):\n",
    "            start_idx = i * segment_size\n",
    "            end_idx = (i + 1) * segment_size\n",
    "            segment_data = eeg_dataframe.iloc[start_idx:end_idx]    \n",
    "            mean_values = segment_data.mean()\n",
    "            sampling_frequency = 1024  \n",
    "            reduced_decomp_df = reduced_decomp_df.append(mean_values, ignore_index=True)\n",
    "        \n",
    "        extract_mean_and_psd_mean(reduced_decomp_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "383c62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv('main_df3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea63dd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Initialize empty lists to store data and labels\n",
    "data = []\n",
    "labels = []\n",
    "raw_eegdata = []\n",
    "\n",
    "for filename in os.listdir(data_dir2):\n",
    "    if filename.endswith('.bdf'):\n",
    "        # Convert the .bdf file to a DataFrame\n",
    "        eeg_data, eeg_raw = convert_bdf_to_dataframe(os.path.join(data_dir2, filename))\n",
    "        \n",
    "        # Extract labels from filenames\n",
    "        label = extract_label_from_filename(filename)\n",
    "#         # Append data and labels\n",
    "        raw_eegdata.append(eeg_raw)\n",
    "    \n",
    "        channel_name_1 = ['O1', 'O2']\n",
    "        channel_name_2 = [\"AF3\", \"AF4\", \"P7\", \"P8\", \"FC5\", \"FC6\", \"T7\", \"T8\", \"Fp1\", \"Fp2\", \"Fpz\"]  # Add more channel names as needed\n",
    "\n",
    "#         # Create dictionaries to store the filtered data\n",
    "        eeg_dataframe = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # Loop through each channel and filter data\n",
    "        for channel_name in channel_name_2:\n",
    "            eeg_channel = eeg_raw.copy().pick_channels([channel_name])\n",
    "    \n",
    "            # Filter for Alpha (8-13 Hz)\n",
    "            alpha_filtered = eeg_channel.filter(l_freq=8, h_freq=13)\n",
    "            alpha_decomp = alpha_filtered.get_data()[0]\n",
    "            eeg_dataframe[f'{channel_name} alpha'] = alpha_decomp\n",
    "    \n",
    "            # Filter for Beta (13-30 Hz)\n",
    "            beta_filtered = eeg_channel.filter(l_freq=13, h_freq=30)\n",
    "            beta_decomp = beta_filtered.get_data()[0]\n",
    "            eeg_dataframe[f'{channel_name} beta'] = beta_decomp\n",
    "    \n",
    "        for channel_name in channel_name_1:\n",
    "            eeg_channel = eeg_raw.copy().pick_channels([channel_name])\n",
    "    \n",
    "            # Filter for Gamma (30-40 Hz)\n",
    "            gamma_filtered = eeg_channel.filter(l_freq=30, h_freq=40)\n",
    "            gamma_decomp = gamma_filtered.get_data()[0]\n",
    "            eeg_dataframe[f'{channel_name} gamma'] = gamma_decomp\n",
    "\n",
    "        # Grouping data for each second\n",
    "        segment_size = 1024\n",
    "        num_segments = len(eeg_dataframe) // segment_size\n",
    "        reduced_decomp_df = pd.DataFrame(columns=eeg_dataframe.columns)\n",
    "        for i in range(num_segments):\n",
    "            start_idx = i * segment_size\n",
    "            end_idx = (i + 1) * segment_size\n",
    "            segment_data = eeg_dataframe.iloc[start_idx:end_idx]    \n",
    "            mean_values = segment_data.mean()\n",
    "            sampling_frequency = 1024  \n",
    "            reduced_decomp_df = reduced_decomp_df.append(mean_values, ignore_index=True)\n",
    "        \n",
    "        extract_mean_and_psd_mean(reduced_decomp_df, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0651f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_csv('main_df1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d0f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('main_df3.csv')\n",
    "\n",
    "# Load the second CSV file into another DataFrame\n",
    "df2 = pd.read_csv('main_df1.csv')\n",
    "\n",
    "# Append df2 to df1\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('merged_dataset_final_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e9cf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('merged_dataset_final_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98c5be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3deed86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3 alpha mean</th>\n",
       "      <th>AF3 alpha psd_mean</th>\n",
       "      <th>AF3 beta mean</th>\n",
       "      <th>AF3 beta psd_mean</th>\n",
       "      <th>AF4 alpha mean</th>\n",
       "      <th>AF4 alpha psd_mean</th>\n",
       "      <th>AF4 beta mean</th>\n",
       "      <th>AF4 beta psd_mean</th>\n",
       "      <th>P7 alpha mean</th>\n",
       "      <th>P7 alpha psd_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fp2 beta psd_mean</th>\n",
       "      <th>Fpz alpha mean</th>\n",
       "      <th>Fpz alpha psd_mean</th>\n",
       "      <th>Fpz beta mean</th>\n",
       "      <th>Fpz beta psd_mean</th>\n",
       "      <th>O1 gamma mean</th>\n",
       "      <th>O1 gamma psd_mean</th>\n",
       "      <th>O2 gamma mean</th>\n",
       "      <th>O2 gamma psd_mean</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.402378e-10</td>\n",
       "      <td>5.356978e-16</td>\n",
       "      <td>3.673941e-11</td>\n",
       "      <td>1.156484e-17</td>\n",
       "      <td>-5.923319e-10</td>\n",
       "      <td>5.714380e-16</td>\n",
       "      <td>2.194584e-11</td>\n",
       "      <td>1.374483e-17</td>\n",
       "      <td>4.221641e-10</td>\n",
       "      <td>1.148155e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.361871e-17</td>\n",
       "      <td>-6.629276e-10</td>\n",
       "      <td>5.598126e-16</td>\n",
       "      <td>-1.856752e-11</td>\n",
       "      <td>1.266935e-17</td>\n",
       "      <td>1.173535e-11</td>\n",
       "      <td>7.829113e-19</td>\n",
       "      <td>2.228500e-11</td>\n",
       "      <td>3.484778e-19</td>\n",
       "      <td>med1breath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.836307e-10</td>\n",
       "      <td>1.463762e-16</td>\n",
       "      <td>-6.057227e-12</td>\n",
       "      <td>9.529278e-18</td>\n",
       "      <td>-5.647640e-10</td>\n",
       "      <td>1.789775e-16</td>\n",
       "      <td>4.804241e-11</td>\n",
       "      <td>1.248500e-17</td>\n",
       "      <td>9.497007e-11</td>\n",
       "      <td>4.112825e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.208274e-17</td>\n",
       "      <td>-4.997515e-10</td>\n",
       "      <td>1.624686e-16</td>\n",
       "      <td>4.063321e-11</td>\n",
       "      <td>1.084634e-17</td>\n",
       "      <td>5.975980e-11</td>\n",
       "      <td>4.053926e-19</td>\n",
       "      <td>6.038006e-11</td>\n",
       "      <td>3.823864e-19</td>\n",
       "      <td>med2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.673828e-10</td>\n",
       "      <td>7.897841e-16</td>\n",
       "      <td>1.744998e-11</td>\n",
       "      <td>1.176160e-17</td>\n",
       "      <td>-1.022646e-09</td>\n",
       "      <td>8.437659e-16</td>\n",
       "      <td>-2.244134e-12</td>\n",
       "      <td>1.417950e-17</td>\n",
       "      <td>-1.833288e-10</td>\n",
       "      <td>1.492559e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.288615e-17</td>\n",
       "      <td>-9.218771e-10</td>\n",
       "      <td>8.113731e-16</td>\n",
       "      <td>8.156524e-12</td>\n",
       "      <td>1.237399e-17</td>\n",
       "      <td>3.610567e-11</td>\n",
       "      <td>4.553950e-19</td>\n",
       "      <td>8.135557e-12</td>\n",
       "      <td>9.183567e-19</td>\n",
       "      <td>think1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.053254e-10</td>\n",
       "      <td>5.912828e-16</td>\n",
       "      <td>-6.295857e-11</td>\n",
       "      <td>8.884157e-18</td>\n",
       "      <td>5.618380e-10</td>\n",
       "      <td>6.208325e-16</td>\n",
       "      <td>-6.218825e-11</td>\n",
       "      <td>1.151538e-17</td>\n",
       "      <td>2.379154e-10</td>\n",
       "      <td>1.015717e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018916e-17</td>\n",
       "      <td>6.104279e-10</td>\n",
       "      <td>6.253911e-16</td>\n",
       "      <td>-9.659438e-11</td>\n",
       "      <td>9.820985e-18</td>\n",
       "      <td>7.245244e-11</td>\n",
       "      <td>5.911956e-19</td>\n",
       "      <td>1.110158e-10</td>\n",
       "      <td>7.396388e-19</td>\n",
       "      <td>think2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.873027e-10</td>\n",
       "      <td>1.139989e-15</td>\n",
       "      <td>-1.993154e-10</td>\n",
       "      <td>1.929155e-17</td>\n",
       "      <td>-4.406758e-10</td>\n",
       "      <td>1.123961e-15</td>\n",
       "      <td>-9.637966e-11</td>\n",
       "      <td>1.963047e-17</td>\n",
       "      <td>4.936242e-10</td>\n",
       "      <td>5.143707e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.720036e-17</td>\n",
       "      <td>-4.561655e-10</td>\n",
       "      <td>1.121919e-15</td>\n",
       "      <td>-1.240375e-10</td>\n",
       "      <td>1.678800e-17</td>\n",
       "      <td>-5.787061e-11</td>\n",
       "      <td>1.017307e-18</td>\n",
       "      <td>3.224554e-11</td>\n",
       "      <td>2.436137e-18</td>\n",
       "      <td>med1breath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>-1.098158e-10</td>\n",
       "      <td>8.828169e-17</td>\n",
       "      <td>-1.552929e-10</td>\n",
       "      <td>9.390739e-18</td>\n",
       "      <td>-5.022041e-11</td>\n",
       "      <td>9.661515e-17</td>\n",
       "      <td>-1.501402e-10</td>\n",
       "      <td>1.003571e-17</td>\n",
       "      <td>1.001916e-10</td>\n",
       "      <td>6.353042e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066868e-17</td>\n",
       "      <td>-2.964541e-11</td>\n",
       "      <td>1.033703e-16</td>\n",
       "      <td>-1.440504e-10</td>\n",
       "      <td>1.077706e-17</td>\n",
       "      <td>4.599238e-11</td>\n",
       "      <td>7.205702e-17</td>\n",
       "      <td>1.189598e-12</td>\n",
       "      <td>1.767439e-18</td>\n",
       "      <td>think2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>-6.446508e-10</td>\n",
       "      <td>1.673368e-15</td>\n",
       "      <td>2.044505e-10</td>\n",
       "      <td>1.212702e-17</td>\n",
       "      <td>-5.760835e-10</td>\n",
       "      <td>1.803364e-15</td>\n",
       "      <td>1.918649e-10</td>\n",
       "      <td>1.436054e-17</td>\n",
       "      <td>-6.191673e-11</td>\n",
       "      <td>2.056511e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304408e-17</td>\n",
       "      <td>-5.207523e-10</td>\n",
       "      <td>1.795228e-15</td>\n",
       "      <td>1.832008e-10</td>\n",
       "      <td>1.214871e-17</td>\n",
       "      <td>-3.354180e-11</td>\n",
       "      <td>5.831825e-19</td>\n",
       "      <td>-3.003426e-11</td>\n",
       "      <td>6.146522e-19</td>\n",
       "      <td>med1breath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>5.076985e-11</td>\n",
       "      <td>2.968612e-16</td>\n",
       "      <td>-3.102505e-10</td>\n",
       "      <td>2.533674e-17</td>\n",
       "      <td>1.703507e-10</td>\n",
       "      <td>3.277631e-16</td>\n",
       "      <td>-3.748135e-10</td>\n",
       "      <td>4.062819e-17</td>\n",
       "      <td>-2.202837e-10</td>\n",
       "      <td>8.033518e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.754514e-17</td>\n",
       "      <td>5.139101e-11</td>\n",
       "      <td>3.255343e-16</td>\n",
       "      <td>-3.669139e-10</td>\n",
       "      <td>3.408049e-17</td>\n",
       "      <td>-4.131331e-11</td>\n",
       "      <td>4.771140e-19</td>\n",
       "      <td>-3.894485e-11</td>\n",
       "      <td>4.450681e-19</td>\n",
       "      <td>med2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>-5.923139e-10</td>\n",
       "      <td>6.431642e-16</td>\n",
       "      <td>-1.658459e-10</td>\n",
       "      <td>1.260369e-17</td>\n",
       "      <td>-5.512093e-10</td>\n",
       "      <td>7.196533e-16</td>\n",
       "      <td>-1.568048e-10</td>\n",
       "      <td>1.561231e-17</td>\n",
       "      <td>-7.559385e-10</td>\n",
       "      <td>1.400364e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.304629e-17</td>\n",
       "      <td>-5.783068e-10</td>\n",
       "      <td>6.812808e-16</td>\n",
       "      <td>-1.725153e-10</td>\n",
       "      <td>1.257172e-17</td>\n",
       "      <td>-1.816352e-10</td>\n",
       "      <td>5.996827e-19</td>\n",
       "      <td>-2.015333e-10</td>\n",
       "      <td>5.794415e-19</td>\n",
       "      <td>think1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>-9.372467e-10</td>\n",
       "      <td>1.066650e-15</td>\n",
       "      <td>5.986617e-11</td>\n",
       "      <td>2.117738e-17</td>\n",
       "      <td>-8.224511e-10</td>\n",
       "      <td>1.138637e-15</td>\n",
       "      <td>7.549588e-11</td>\n",
       "      <td>2.367037e-17</td>\n",
       "      <td>-3.567423e-10</td>\n",
       "      <td>1.838266e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.239279e-17</td>\n",
       "      <td>-9.972706e-10</td>\n",
       "      <td>1.118956e-15</td>\n",
       "      <td>3.538453e-12</td>\n",
       "      <td>2.194375e-17</td>\n",
       "      <td>8.135260e-12</td>\n",
       "      <td>5.583698e-19</td>\n",
       "      <td>2.225045e-11</td>\n",
       "      <td>5.888262e-19</td>\n",
       "      <td>think2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AF3 alpha mean  AF3 alpha psd_mean  AF3 beta mean  AF3 beta psd_mean  \\\n",
       "0     -5.402378e-10        5.356978e-16   3.673941e-11       1.156484e-17   \n",
       "1     -4.836307e-10        1.463762e-16  -6.057227e-12       9.529278e-18   \n",
       "2     -9.673828e-10        7.897841e-16   1.744998e-11       1.176160e-17   \n",
       "3      5.053254e-10        5.912828e-16  -6.295857e-11       8.884157e-18   \n",
       "4     -4.873027e-10        1.139989e-15  -1.993154e-10       1.929155e-17   \n",
       "..              ...                 ...            ...                ...   \n",
       "583   -1.098158e-10        8.828169e-17  -1.552929e-10       9.390739e-18   \n",
       "584   -6.446508e-10        1.673368e-15   2.044505e-10       1.212702e-17   \n",
       "585    5.076985e-11        2.968612e-16  -3.102505e-10       2.533674e-17   \n",
       "586   -5.923139e-10        6.431642e-16  -1.658459e-10       1.260369e-17   \n",
       "587   -9.372467e-10        1.066650e-15   5.986617e-11       2.117738e-17   \n",
       "\n",
       "     AF4 alpha mean  AF4 alpha psd_mean  AF4 beta mean  AF4 beta psd_mean  \\\n",
       "0     -5.923319e-10        5.714380e-16   2.194584e-11       1.374483e-17   \n",
       "1     -5.647640e-10        1.789775e-16   4.804241e-11       1.248500e-17   \n",
       "2     -1.022646e-09        8.437659e-16  -2.244134e-12       1.417950e-17   \n",
       "3      5.618380e-10        6.208325e-16  -6.218825e-11       1.151538e-17   \n",
       "4     -4.406758e-10        1.123961e-15  -9.637966e-11       1.963047e-17   \n",
       "..              ...                 ...            ...                ...   \n",
       "583   -5.022041e-11        9.661515e-17  -1.501402e-10       1.003571e-17   \n",
       "584   -5.760835e-10        1.803364e-15   1.918649e-10       1.436054e-17   \n",
       "585    1.703507e-10        3.277631e-16  -3.748135e-10       4.062819e-17   \n",
       "586   -5.512093e-10        7.196533e-16  -1.568048e-10       1.561231e-17   \n",
       "587   -8.224511e-10        1.138637e-15   7.549588e-11       2.367037e-17   \n",
       "\n",
       "     P7 alpha mean  P7 alpha psd_mean  ...  Fp2 beta psd_mean  Fpz alpha mean  \\\n",
       "0     4.221641e-10       1.148155e-16  ...       1.361871e-17   -6.629276e-10   \n",
       "1     9.497007e-11       4.112825e-17  ...       1.208274e-17   -4.997515e-10   \n",
       "2    -1.833288e-10       1.492559e-16  ...       1.288615e-17   -9.218771e-10   \n",
       "3     2.379154e-10       1.015717e-16  ...       1.018916e-17    6.104279e-10   \n",
       "4     4.936242e-10       5.143707e-16  ...       1.720036e-17   -4.561655e-10   \n",
       "..             ...                ...  ...                ...             ...   \n",
       "583   1.001916e-10       6.353042e-17  ...       1.066868e-17   -2.964541e-11   \n",
       "584  -6.191673e-11       2.056511e-16  ...       1.304408e-17   -5.207523e-10   \n",
       "585  -2.202837e-10       8.033518e-17  ...       3.754514e-17    5.139101e-11   \n",
       "586  -7.559385e-10       1.400364e-16  ...       1.304629e-17   -5.783068e-10   \n",
       "587  -3.567423e-10       1.838266e-16  ...       2.239279e-17   -9.972706e-10   \n",
       "\n",
       "     Fpz alpha psd_mean  Fpz beta mean  Fpz beta psd_mean  O1 gamma mean  \\\n",
       "0          5.598126e-16  -1.856752e-11       1.266935e-17   1.173535e-11   \n",
       "1          1.624686e-16   4.063321e-11       1.084634e-17   5.975980e-11   \n",
       "2          8.113731e-16   8.156524e-12       1.237399e-17   3.610567e-11   \n",
       "3          6.253911e-16  -9.659438e-11       9.820985e-18   7.245244e-11   \n",
       "4          1.121919e-15  -1.240375e-10       1.678800e-17  -5.787061e-11   \n",
       "..                  ...            ...                ...            ...   \n",
       "583        1.033703e-16  -1.440504e-10       1.077706e-17   4.599238e-11   \n",
       "584        1.795228e-15   1.832008e-10       1.214871e-17  -3.354180e-11   \n",
       "585        3.255343e-16  -3.669139e-10       3.408049e-17  -4.131331e-11   \n",
       "586        6.812808e-16  -1.725153e-10       1.257172e-17  -1.816352e-10   \n",
       "587        1.118956e-15   3.538453e-12       2.194375e-17   8.135260e-12   \n",
       "\n",
       "     O1 gamma psd_mean  O2 gamma mean  O2 gamma psd_mean        task  \n",
       "0         7.829113e-19   2.228500e-11       3.484778e-19  med1breath  \n",
       "1         4.053926e-19   6.038006e-11       3.823864e-19        med2  \n",
       "2         4.553950e-19   8.135557e-12       9.183567e-19      think1  \n",
       "3         5.911956e-19   1.110158e-10       7.396388e-19      think2  \n",
       "4         1.017307e-18   3.224554e-11       2.436137e-18  med1breath  \n",
       "..                 ...            ...                ...         ...  \n",
       "583       7.205702e-17   1.189598e-12       1.767439e-18      think2  \n",
       "584       5.831825e-19  -3.003426e-11       6.146522e-19  med1breath  \n",
       "585       4.771140e-19  -3.894485e-11       4.450681e-19        med2  \n",
       "586       5.996827e-19  -2.015333e-10       5.794415e-19      think1  \n",
       "587       5.583698e-19   2.225045e-11       5.888262e-19      think2  \n",
       "\n",
       "[588 rows x 49 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e03257",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = main_df.drop('task', axis = 1)\n",
    "y = main_df['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "626fdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_min = min_max_scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_min, y_encoded, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3208386e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.288135593220339"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Create a Random Forest classifier (you can try other classifiers as well)\n",
    "clf = LogisticRegression(random_state=11)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95156074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3898305084745763\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c575bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eb656b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711864406779661"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Standardize the features (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79cb5832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an SVM classifier\n",
    "clf = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4704b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Print the importance of each feature\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature, importance \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns, feature_importances):\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimportance\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test data (optional)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Print the importance of each feature\n",
    "for feature, importance in zip(X.columns, feature_importances):\n",
    "    print(f'{feature}: {importance:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define a neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(len(class_labels), activation='softmax')  # Output layer with softmax activation\n",
    "])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Use categorical cross-entropy\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert target labels to one-hot encoding\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, len(class_labels))\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, len(class_labels))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_one_hot, epochs=100, batch_size=64, validation_split=0.2, callbacks=[callback])\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predicted labels back to string labels\n",
    "predicted_labels = [class_labels[np.argmax(pred)] for pred in predictions]\n",
    "predicted_labels_encoded = label_encoder.transform(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c23f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Assuming you have your data loaded as X_train, y_train, X_test, y_test\n",
    "num_unique_values = X_train.shape[0]\n",
    "input_sequence_length = 28\n",
    "embedding_dim = 1\n",
    "# Define the CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(input_dim=num_unique_values, output_dim=embedding_dim, input_length=input_sequence_length),\n",
    "    layers.Conv1D(128, 5, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(64, 5, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f10e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_test contains true labels and predicted_labels contains predicted labels\n",
    "# These should be NumPy arrays or Python lists.\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, predicted_labels_encoded)\n",
    "\n",
    "# Display the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3507beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Replace these with your actual predicted and true labels\n",
    "predicted_labels = y.unique()\n",
    "true_labels = y.unique()\n",
    "\n",
    "# Get the unique class names from the labels\n",
    "class_names = np.unique(true_labels)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion = confusion_matrix(true_labels, predicted_labels, labels=class_names)\n",
    "\n",
    "# Create a heatmap to visualize the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(confusion, annot=True, fmt='d', cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# You can also print a classification report with precision, recall, and F1-score\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bb1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da116e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
